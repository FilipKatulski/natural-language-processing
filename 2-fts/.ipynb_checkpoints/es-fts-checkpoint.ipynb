{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - FTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import functools\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ElasticSearch communicates through REST API. In the development process of this notebook the ES instance's security features such as SSL were disabled to allow unrestricted access. This was necessary to not use SSL keys/certs or to not point to the their location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'MacBook-Pro-5.lan',\n",
       " 'cluster_name': 'elasticsearch',\n",
       " 'cluster_uuid': 'PooxqAlHSxyYoL2hC3MGDw',\n",
       " 'version': {'number': '8.4.3',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'tar',\n",
       "  'build_hash': '42f05b9372a9a4a470db3b52817899b99a76ee73',\n",
       "  'build_date': '2022-10-04T07:17:24.662462378Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '9.3.0',\n",
       "  'minimum_wire_compatibility_version': '7.17.0',\n",
       "  'minimum_index_compatibility_version': '7.0.0'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host = \"http://localhost:9200\"\n",
    "es = Elasticsearch(host)\n",
    "es.info().body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "polish_analyzer = \"polish_law_analyzer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'polish_law_index'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks if indices already exist, if so deletes them.\n",
    "if es.indices.exists(index=\"polish_law_index\"):\n",
    "    es.indices.delete(index=\"polish_law_index\")\n",
    "\n",
    "response = es.indices.create(\n",
    "    index=\"polish_law_index\",\n",
    "    settings={\n",
    "        'analysis': {\n",
    "            'analyzer': {\n",
    "                f'{polish_analyzer}': {\n",
    "                    'type': 'custom',\n",
    "                    'tokenizer': 'standard',\n",
    "                    'filter': [\n",
    "                        \"lowercase\",  # lowercase filter\n",
    "                        \"synonym\",  # introduce synonyms, defined below\n",
    "                        \"morfologik_stem\"  # Morfologic as the lemmatizer\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            'filter': {\n",
    "                'synonym': {\n",
    "                    'type': \"synonym\",\n",
    "                    'expand': True,  # TODO\n",
    "                    'synonyms': [\n",
    "                        \"kpk => kodeks postępowania karnego\",\n",
    "                        \"kpc => kodeks postępowania cywilnego\",\n",
    "                        \"kk => kodeks karny\",\n",
    "                        \"kc => kodeks cywilny\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    mappings={\n",
    "        'properties': {\n",
    "            'text': {\n",
    "                'type': \"text\",\n",
    "                'analyzer': f'{polish_analyzer}',\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading documents and uploading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_folder = \"ustawy\"\n",
    "\n",
    "def read_documents() -> dict[str, str]:\n",
    "    file_names = os.listdir(files_folder)\n",
    "    return {\n",
    "        name: _read_document(name, files_folder)\n",
    "        for name in file_names\n",
    "        if name.endswith(\".txt\")\n",
    "    }\n",
    "\n",
    "def _read_document(name: str, path: str) -> str:\n",
    "    with open(os.path.join(path, name), 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "documents = list(read_documents().items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_document_to_action(doc_name: str) -> dict:\n",
    "    return {\n",
    "        'index': {\n",
    "            '_id': doc_name,\n",
    "        }\n",
    "    }\n",
    "\n",
    "def map_document_to_source(doc_name: str, doc_text: str) -> dict:\n",
    "    return {\n",
    "        'name': doc_name,\n",
    "        'text': doc_text\n",
    "    }\n",
    "\n",
    "def bulk_documents(documents: list[tuple[str, str]]) -> list[dict]:\n",
    "    return functools.reduce(\n",
    "        lambda acc, x: acc + [map_document_to_action(x[0])] + [map_document_to_source(*x)],\n",
    "        documents,\n",
    "        []\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5: Load the data to the ES instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading chunk 1/4\n",
      "Took: 1112, errors: False\n",
      "Uploading chunk 2/4\n",
      "Took: 604, errors: False\n",
      "Uploading chunk 3/4\n",
      "Took: 997, errors: False\n",
      "Uploading chunk 4/4\n",
      "Took: 622, errors: False\n"
     ]
    }
   ],
   "source": [
    "n = 300\n",
    "documents_chunked = [documents[i:i + n] for i in range(0, len(documents), n)]\n",
    "n_chunks = len(documents_chunked)\n",
    "for i, docs in enumerate(documents_chunked, 1):\n",
    "    print(f\"Uploading chunk {i}/{n_chunks}\")\n",
    "    res = es.bulk(index=\"doc\", operations=bulk_documents(docs))\n",
    "    print(f\"Took: {res['took']}, errors: {res['errors']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6: Determine the number of legislative acts containing the word ustawa (in any form)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of the word 'ustawa': 1178\n"
     ]
    }
   ],
   "source": [
    "response = es.count(\n",
    "    index=\"doc\", \n",
    "    query={'match': {'text': {'query': \"ustawa\"}}}\n",
    "    )\n",
    "count_ustawa = response['count']\n",
    "print(\"Count of the word 'ustawa':\", count_ustawa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7: Determine the number of occurrences of the word ustawa by searching for this particular form, including the other inflectional forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'term_vectors': {'text': {'terms': {'ustawa': {'ttf': 3235}}}}}\n",
      "Number of occurrences of the word \"ustawa\": 3235\n"
     ]
    }
   ],
   "source": [
    "response = es.termvectors(\n",
    "    index=\"doc\",\n",
    "    id=\"1993_602.txt\",  # first file in the folder\n",
    "    fields=[\"text\"],\n",
    "    filter_path=[\"term_vectors.text.terms.ustawa.ttf\"],\n",
    "    term_statistics=True\n",
    ")\n",
    "print(response)\n",
    "ttf_ustawa = response['term_vectors']['text']['terms']['ustawa']['ttf']\n",
    "print('Number of occurrences of the word \"ustawa\":', ttf_ustawa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 8: Determine the number of occurrences of the word ustaw by searching for this particular form, including the other inflectional forms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ES_ANALYZER' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m response \u001b[38;5;241m=\u001b[39m es\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39manalyze(\n\u001b[1;32m      2\u001b[0m     index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m----> 3\u001b[0m     analyzer\u001b[38;5;241m=\u001b[39m\u001b[43mES_ANALYZER\u001b[49m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# analyzer='polish_law_analyzer',\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mustaw\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n\u001b[1;32m      8\u001b[0m words_ustaw \u001b[38;5;241m=\u001b[39m [t[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ES_ANALYZER' is not defined"
     ]
    }
   ],
   "source": [
    "response = es.indices.analyze(\n",
    "    index=\"doc\",\n",
    "    analyzer=ES_ANALYZER,\n",
    "    # analyzer='polish_law_analyzer',\n",
    "    text=\"ustaw\" \n",
    ")\n",
    "print(response)\n",
    "words_ustaw = [t['token'] for t in response['tokens']]\n",
    "words_ustaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': [{'token': 'ustaw', 'start_offset': 0, 'end_offset': 5, 'type': '<ALPHANUM>', 'position': 0}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ustaw']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The problem with selecting \"polish_law_analyzer\", finds the word \"ustaw\" in indices without specified analyzer\n",
    "\n",
    "response = es.indices.analyze(\n",
    "    index=\"doc\",\n",
    "    # analyzer=polish_analyzer, \n",
    "    text=\"ustaw\" \n",
    ")\n",
    "print(response)\n",
    "words_ustaw = [t['token'] for t in response['tokens']]\n",
    "words_ustaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 9: Determine the number of legislative acts containing the words 'kodeks postępowania cywilnego' in the specified order, but in any inflection form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 'kodeks postepowanie cywilnego': 44\n"
     ]
    }
   ],
   "source": [
    "response = es.count(\n",
    "    index=\"doc\", \n",
    "    query={'match_phrase': {'text': \"kodeks postępowania cywilnego\"}}\n",
    "    )\n",
    "count_kpc = response['count']\n",
    "print(\"Count of 'kodeks postepowanie cywilnego':\", count_kpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 10: Determine the number of legislative acts containing the words 'wchodzi w życie' (in any form) allowing for up to 2 additional words in the searched phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 1174, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n",
      "Number of documents containing the phrase 'wchodzi w życie': 1174\n"
     ]
    }
   ],
   "source": [
    "response = es.count(\n",
    "    index=\"doc\", \n",
    "    query={'match_phrase': {'text': {'query': \"wchodzi w życie\", 'slop': 2}}}\n",
    ")\n",
    "print(response)\n",
    "count_wwz = response['count']\n",
    "print(\"Number of documents containing the phrase 'wchodzi w życie':\", count_wwz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 11: Determine the 10 documents that are the most relevant for the phrase konstytucja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hits': {'hits': [{'_id': '1997_629.txt', '_score': 9.633655}, {'_id': '1999_688.txt', '_score': 7.6440825}]}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'_id': '1997_629.txt', '_score': 9.633655},\n",
       " {'_id': '1999_688.txt', '_score': 7.6440825}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"konstytucja\"\n",
    "\n",
    "res = es.search(\n",
    "    index=\"doc\",\n",
    "    query={'match': {'text': word}},\n",
    "    filter_path=[\"hits.hits._id\", \"hits.hits._score\"],\n",
    "    size=10\n",
    ")\n",
    "print(res)\n",
    "res[\"hits\"][\"hits\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 12: Print the excerpts containing the word konstytucja (up to three excerpts per document) from the previous task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hits': {'hits': [{'_id': '1997_629.txt', 'highlight': {'text': ['Zasady, na których opierać się ma <em>Konstytucja</em> mogą\\n                być poddane pod referendum.']}}, {'_id': '1999_688.txt', 'highlight': {'text': ['Projekt ustawy nie może dotyczyć spraw, dla których <em>Konstytucja</em>\\nRzeczypospolitej Polskiej zastrzega wyłączną']}}]}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'_id': '1997_629.txt',\n",
       "  'highlight': {'text': ['Zasady, na których opierać się ma <em>Konstytucja</em> mogą\\n                być poddane pod referendum.']}},\n",
       " {'_id': '1999_688.txt',\n",
       "  'highlight': {'text': ['Projekt ustawy nie może dotyczyć spraw, dla których <em>Konstytucja</em>\\nRzeczypospolitej Polskiej zastrzega wyłączną']}}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = es.search(\n",
    "    index=\"doc\",\n",
    "    query={'match': {'text': \"konstytucja\"}},\n",
    "    highlight={'fields': {'text': {'number_of_fragments': 3}}},\n",
    "    filter_path=[\"hits.hits._id\", \"hits.hits.highlight\"],\n",
    "    size=10\n",
    ")\n",
    "print(response)\n",
    "response['hits']['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a447cce11633770116628ba2ec33bfc43075824ffa0595b2fdbcb87d335f18be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
